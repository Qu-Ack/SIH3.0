# SIH3.0
PSI 1431
           1) subject
           2) chapter
           3) required topic
    a) teacher best                          b) teacher which teaches
    for required topic                           this chapter
                             
                             after watching  video
                             rating   (*necessary)
                                         {as it help other }


                                         10min test
                                         a) subjective
                                         b) objective

                       10 points(by from there store)
                       4000 points(100rs)
                       1lakh points par student pass(amazon or online store)
                       1 -1000
                       free

            

psi(1392)
last e-waste facility update in india 2021

first our target is where is larger E-waste in india not where is more population 
 India's major metropolitan cities, such as Mumbai, Delhi, Bengaluru, Chennai, and Kolkata, have higher population densities and greater urbanization. These cities typically have a higher concentration of e-waste facilities and a larger user base for e-waste facility locators due to increased electronic device usage.

 IT Hubs: 
 Cities like Bengaluru (often referred to as the Silicon Valley of India) and Hyderabad, which are known for their IT and technology sectors, tend to have a larger use of e-waste facility locators. The tech-savvy population in these cities is more likely to engage in responsible e-waste disposal.

Urban and Industrial Regions: 
Regions with high levels of industrial and commercial activity, such as Gujarat (especially around Ahmedabad), Pune (in Maharashtra), and Noida (in Uttar Pradesh), (may*****) have a larger usage of e-waste facility locators due to the generation of electronic waste from industries and businesses.

psi 1326

Ideate and implement a system to enhance the quality of education in rural areas.
Description	
Ideate and implement a system to enhance the quality of education in rural areas. The aim of the system should not only focus on increasing the literacy rate but also should assist to elevate the communication skills and knowledge of the targeted society. The system should offer : * Study materials and mentor access. * Monitoring skill progress * Bridge the digital divide * Provide information about grants, loans and incentives. * Offer connectivity to financially disadvantage patrons. * Help individuals with employment opportunities. * Research and development * Access to material resources

psi 1362
Student dropout analysis for school education
Description	
Right to education is key concern for government and at school level; drop out ratio is high due to poverty and social, economic reasons. If government have drop out student analysis on following different categories, it will be very useful in framing different policies. 1. School wise 2. Area wise 3. Gender wise 4. Caste wise 5. Age/standard wise Expected Output: Focused interventions on the high dropout rates


Sarthak ->

3 of 5 topics are on chatbots, learning machine learning from scratch can take months, probably dropped ideas.
1 topic is based on AR therefore too difficult to implement
PS ID 1317 is different, read more

1) PS ID 1317 

What we want ->
An app to access a map which shows real time location and destinations of coal transporters.
"The platform should leverage image analytics, data integration, and advanced visualization techniques to provide real-time insights into the LOCATION, STATUS, and CONDITION of coal shipments"

1. Tracking Transportation ->
    > Main focus is to make a map which plots real time location of coal transporaters.
        Display login screen.
        Depending who logs in, show different features
        > Admin
            Can access map + status + condition, basically all the monitering stuff
        > Transporter
            Can access features like uploading pics and details of shipments.
            Will apply the starting position and destination of coal shipment.

    > Needs GPS, use free/paid apis for converting ip address to lattitude and longitudes, then import it into your map/system which will display it.
    > Will probably use Google's APIs for all mapping
    > Main way to get coal's location will be to use a smartphone.
    > To allow the coal transporter to upload his/her location, login accounts based on regions and individuals will be used
    > Person accessing the smartphone will have to run routine checks on the coal shipments for CONDITION.
    > App has to ask the person for the STATUS if there is some sort of delay.
    > To allow the coal transporter to upload his/her location, login accounts based on regions and individuals     will be used

2. Staus + Condition of coal shipments ->
    > Person accessing the smartphone will have to run routine checks on the coal shipments for CONDITION.
    > App has to ask the person for the STATUS if there is some sort of delay.

3. Prequistives ->
    > A good amount of Javascript to access APIs
    > Web/App development, depending on what we make
    > MAYBE Python

4. Extra Features? ->
    > Report option if coal doesn't reach but shows that the shipment is complete


2) PS ID 1312 (CHATBOT)

What we want -> Chatbot to respond text queries regarding Acts, Rules and Regulations applicable to Mining Industry
"A Chatbot is a computer program that uses ARTIFICAL INTELLIGENCE (AI) and NATURAL LANGUANGE PROCESSING (NLP) to understand customer questions and automate responses to them, imitating human conversation."

1. AI and NLP->
    > NLP = "the application of computational techniques to the analysis and synthesis of natural language and speech."
    > Will need to learn PYTHON and AI + MACHINE LEARNING to even have a chance at creating a NLP from scratch
    OR use chatgpt's API (paid) and train it to focus on Mining Industry.
    > Refer Sr no. 4) for more info on designing chatbots.


3) PS ID 1303 (NEEDS AUGMENETED REALITY) (dropped)

What we want -> 
1. The application should accommodate the AR feature. As the candidate uses the smartphone camera (i) A notification would be received on the screen about the jobs or gig jobs or skill development initiatives or foreign counseling initiatives available in that area. (ii) The details should also be made available on the screen. (iii) A weblink should be available that navigates to the webpage where the candidate can successfully apply for the job or the gig. 2. The GPS feature should be integrated to generate an interface that enables the employers (demand side) to view the prospective registered candidates having desired skills for a specific job. This the information must be available in real-time based on the geographical coordinates of the candidate and employer. 3. The app should be able to push notifications to candidates’ smartphone about a job, skill development, or foreign counseling based on their geospatial coordinates. 4. The app should also be able to maintain candidates’ history and preferences to add a level of personalization for better recommendations. The app should employ Machine Learning (ML), Data Science, Deep Learning, Augmented Reality (AR), Global Positioning System (GPS) Expected Outcome User should be able to find jobs at any location and can even find jobs on his camera phone as and when he points the camera on a particular building/ location within a geographical area.


4) PS ID 1290 (CHATBOT)

What we want -> 
An interactive robot named “Chacha Chaudhary” would be the Artificial intelligence & machine learning & chat boat-enabled mascot of the Namami Gange made with the help of a touch panel, greets visitors at the entrance and takes them along to each component of the NANAMI GANGE FLAGSHIP program in River Basin War Room & Ganga Museum. The digital avatar of Chacha Chaudhary would also enable on the NMCG website. Robot Mascot (Chacha Chaudhary) & digital avatar solution would be providing to actively engage with citizens to impart information, awareness, and education around riverine ecology in an interactive format of digital and outdoor installations. Sample Data Required: 
1. https://nmcg.nic.in/ 
2. http://cganga.org/scientific-advisory-committee/ 
3. http://nihroorkee.gov.in/Gangakosh/ganga.htm 
4. http://gangapedia.in/ 
5. https://www.gangaaction.org/ganga-gyan-dhara-samgra-samvaad-workshop-for-clean-ganga/ 
6. https://clap4ganga.com/

1. Display + Interface ->
    > Will need a good amount of knowledge on Javascript
2. The actual AI (from chatgpt)->
    > Define Your Topic:
        Clearly define the specific topic or domain you want your language model to focus on. The narrower and more well-defined your topic, the better.

    > Data Collection:
        Gather a substantial amount of text data related to your chosen topic. You can scrape websites, collect research papers, or access relevant datasets. Ensure that the data is diverse and representative of the topic's various aspects.
        (Already provided in description)

    > Data Preprocessing:
        Clean and preprocess the collected data. This involves tasks like removing duplicates, handling special characters, tokenization, and possibly stemming or lemmatization depending on the language.
        (Modify data)

    > Annotation and Labeling (Optional):
        If your task requires specific annotations or labels, you may need to annotate your data. For example, if you're building a sentiment analysis model, you'll need labeled data indicating the sentiment of each text.

    > Model Selection:
        Choose the appropriate type of model for your task. For most natural language processing (NLP) tasks, pre-trained transformer models like GPT-3 or its successors are a good starting point. Depending on your resources, you can either train from scratch or fine-tune a pre-existing model.
        (Here comes the actual machine learning, either make it from scratch, or use pre trained models)

    > Fine-tuning (if using pre-trained model):
        If you decide to fine-tune a pre-trained model, create a smaller dataset from your domain-specific data and use it to fine-tune the model. Fine-tuning helps adapt the model to your specific topic.

    > Model Training:
        Train your model on the preprocessed and annotated data. Ensure that you have access to sufficient computational resources, as training a large language model can be computationally intensive and time-consuming.

    > Evaluation:
        Evaluate your model's performance using appropriate metrics for your specific task (e.g., accuracy, F1 score, perplexity, etc.). You may need a validation set or cross-validation to assess how well your model generalizes to new data.

    > Iterative Improvement:
        Based on the evaluation results, make necessary adjustments to your model's architecture, hyperparameters, or dataset. Training an effective language model often involves several iterations of fine-tuning and evaluation.

    > Deployment:
        Once you're satisfied with the model's performance, you can deploy it as an API, a web application, or integrate it into your desired application or platform.

    > Monitoring and Maintenance:
        Continuously monitor your language model in a production environment, as language can evolve over time. Retrain or update the model as needed to keep it accurate and relevant.


5) PS ID 1380 (CHATBOT)

What we want ->
Intelligent chatbot to answer queries pertaining to various Maintenance Processes within Substation (aka the place all maintenance will take place)

1. Chatbot stuff -> Refer 4) PS ID 1290
2. Rsearching documents on maintaenance catgeories and stuff for each equipment


DAKSH->

PSID 1417 AI-ML based intelligent de-smoking/de-hazing algorithm

steps 

1. Data Collection => A set of images that will be used to detect fires. (https://www.kaggle.com/datasets/phylake1337/fire-dataset)
2. Data Augmentation => This include processing the data . First cleaning the data , removing any corrupted files then rotating , resizing , adding random noise , Brightness and other stuff.
3. Data Splitting => 
Random Shuffling: Before splitting, it's a good practice to shuffle your dataset randomly. This      ensures that the data in each subset is representative of the entire dataset and prevents any bias due to ordering.

Training Set: Allocate the majority of your data to the training set, typically around 70-80% of the total dataset. The model learns from this data.Validation Set: Set aside a smaller portion, typically around 10-15%, for the validation set. This set is used to fine-tune hyperparameters and assess the model's performance during training.

Test Set: Reserve another portion, usually the same size as the validation set (10-15%), for the test set. The test set is used for final model evaluation and should not be used for model training or hyperparameter tuning.

4. Model Selection => CNN networks are used but are very complex

5. Making the model => Maa chud jayegi isko banane me "Compile the model by specifying the optimizer, loss function, and evaluation metrics. The choice of optimizer and loss function depends on your specific problem. For binary classification (fire vs. non-fire), you can use the Adam optimizer and binary cross-entropy loss." ye chat gpt ka answer 




PSID 1369 Online integrated platform for projects taken up by the students of various universities/colleges


1. TO build a solid landing page along with a sign up / login form
2. TO build a dashboard for the user containing his uploaded projects and a feature to upload new projects
3. we can add a feature where user can get points on the number of projects he has uploaded and other fun features like this to make our project stand out. 
4. to build a database where we will store user's information and all the projects uploaded
5. to build a search feature where user can search for projects uploaded and filter them uni wise. 


PSID 1431 Online personalized learning remediation/tutoring tool. Search for best teacher for specific topics.

1. We need to know the teachers for that we take feedback from students and that gives us the best teachers of particular topics
2. we need to know the students. we conduct tests and in that test we analyze the students performance and we pinpoint the topics that he blundered. 
3. We connect the student with the teacher of that particular topic 
4. at the end we give the student a performance report.


PSID 1367 To develop a technical solution for enabling Institution level verification of students of one State studying in other State/s, who are at present generally denied benefits under the Scholarship scheme as the Institutions in which they are studying are not registered on the portal/s of their home State.


